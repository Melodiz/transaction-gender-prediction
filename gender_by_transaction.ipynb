{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Predicting Client Gender </center>\n",
    "\n",
    "### It is necessary to identify the gender of the client based on their transactional historical data. The quality metric is [ROC AUC](https://dyakonov.org/2017/07/28/auc-roc-%D0%BF%D0%BB%D0%BE%D1%89%D0%B0%D0%B4%D1%8C-%D0%BF%D0%BE%D0%B4-%D0%BA%D1%80%D0%B8%D0%B2%D0%BE%D0%B9-%D0%BE%D1%88%D0%B8%D0%B1%D0%BE%D0%BA/), which needs to be maximized."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-23T13:11:26.066752Z",
     "iopub.status.busy": "2021-08-23T13:11:26.065958Z",
     "iopub.status.idle": "2021-08-23T13:11:26.073084Z",
     "shell.execute_reply": "2021-08-23T13:11:26.072336Z",
     "shell.execute_reply.started": "2021-08-23T13:11:26.066698Z"
    }
   },
   "source": [
    "## File Descriptions\n",
    "- transactions.csv - historical transactions of bank clients\n",
    "- gender.csv - gender information for some clients (null for test clients)\n",
    "- tr_mcc_codes.csv - mcc codes of transactions\n",
    "- tr_types.csv - types of transactions\n",
    "\n",
    "## Field Descriptions\n",
    "### transactions.csv\n",
    "- client_id - client identifier\n",
    "- tr_datetime - date and time of the transaction (days are numbered from the start of the data)\n",
    "- mcc_code - mcc code of the transaction\n",
    "- tr_type - type of transaction\n",
    "- amount - transaction amount in conditional units; with a \"+\" sign — funds credited to the client, \"-\" — funds debited\n",
    "- term_id - terminal identifier\n",
    "\n",
    "### gender.csv\n",
    "- client_id - client identifier\n",
    "- gender - client gender (empty values for test clients)\n",
    "\n",
    "### tr_mcc_codes.csv\n",
    "- mcc_code - mcc code of the transaction\n",
    "- mcc_description - description of the mcc code\n",
    "\n",
    "### tr_types.csv\n",
    "- tr_type - type of transaction\n",
    "- tr_description - description of the transaction type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Tasks:\n",
    "- Develop a binary classification model to determine the client's gender. There are no restrictions on the model - it can be anything from KNN to transformers. The main goal is to achieve an ROC AUC above 77.5% on the hold-out test set.\n",
    "- Interpret the model results: the importance of the variables included in it, demonstrating on several examples why the corresponding prediction was made. This will help understand which gender corresponds to which target (0/1). Again, there is complete freedom of choice of approaches! Useful keywords: gain, permutation importance, SHAP.\n",
    "- Convert the results into a report without code (ideally - directly into [html](https://stackoverflow.com/questions/49907455/hide-code-when-exporting-jupyter-notebook-to-html))\n",
    "\n",
    "#### P.S. Don't forget about [PEP8](https://www.python.org/dev/peps/pep-0008/)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier, \\\n",
    "                             GradientBoostingClassifier, \\\n",
    "                             RandomForestClassifier \\\n",
    "                            #  BaggingClassifier,\\\n",
    "                            #  StackingClassifier, \\\n",
    "                            #  VotingClassifier\n",
    "# from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# from sklearn.linear_model import LogisticRegressionCV\n",
    "# from lightgbm import LGBMClassifier\n",
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from operator import itemgetter\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(action = 'ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Объединение датасетов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_mcc_codes = pd.read_csv(\"data/mcc_codes.csv\", sep=\";\", index_col=\"mcc_code\")\n",
    "tr_types = pd.read_csv(\"data/trans_types.csv\", sep=\";\", index_col=\"trans_type\")\n",
    "\n",
    "transactions = pd.read_csv(\"data/transactions.csv\", index_col=\"client_id\")\n",
    "test_gender = pd.read_csv(\"data/test.csv\", index_col=\"client_id\")\n",
    "train_gender = pd.read_csv(\"data/train.csv\", index_col=\"client_id\")\n",
    "gender = pd.concat([train_gender, test_gender]).drop('Unnamed: 0', axis=1)\n",
    "\n",
    "del test_gender, train_gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_mcc_codes.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_types.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = transactions\n",
    "df = df.join(gender)\n",
    "df = pd.merge(df, tr_types, left_on=\"trans_type\", right_index=True)\n",
    "df = pd.merge(df, tr_mcc_codes, left_on=\"mcc_code\", right_index=True)\n",
    "del transactions, tr_types, tr_mcc_codes, gender\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[df['gender'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def missing_features(data, column_set):\n",
    "    incomplete_features = {feature: data.shape[0]-sum(data[feature].value_counts())\n",
    "                                   for feature in column_set\n",
    "                                   if not sum(data[feature].value_counts()) == data.shape[0]}\n",
    "    incomplete_features_sorted = sorted(incomplete_features, key=lambda feature: incomplete_features[feature], reverse=True)\n",
    "    incompleteness = [round((incomplete_features[feature]/data.shape[0])*100, 2) for feature in incomplete_features_sorted]\n",
    "    \n",
    "    for feature, percentage in zip(incomplete_features_sorted, incompleteness):\n",
    "        print(f'{feature} {incomplete_features[feature]} ({percentage}%)')\n",
    "missing_features(df, df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df['amount'], bins=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Corelation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "sns.heatmap(\n",
    "    df.select_dtypes(include=[np.number]).corr(),  # Select only numerical columns\n",
    "    annot=True,\n",
    "    fmt='.2f',\n",
    "    # cmap='coolwarm'\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['earned'] = [0 if i <0 else 1 for i in df['amount']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['day'] = pd.DataFrame(df[\"trans_time\"].str.split(' ', expand = True)[0]).astype(\"int64\").fillna(0)\n",
    "df['time'] = pd.DataFrame(df[\"trans_time\"].str.split(' ', expand = True)[1].str.split(':', expand = True)[0]).astype(\"int64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['total'] = df.groupby(['client_id'])[\"amount\"].sum().fillna(0)\n",
    "df['total_spent'] = df.loc[df['earned'] == 0].groupby(['client_id'])[\"amount\"].sum().fillna(0)\n",
    "df['total_earned'] = df.loc[df['earned'] == 1].groupby(['client_id'])[\"amount\"].sum().fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"avg_amount_per_day\"] = df.groupby(['client_id','day'])[\"amount\"].transform('mean').fillna(0)\n",
    "df[\"var_amount_per_day\"] = df.groupby(['client_id','day'])[\"amount\"].transform('std').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['avg_sum_per_transaction'] = df.groupby(['client_id'])['amount'].mean().fillna(0)\n",
    "df['avg_sum_spent_per_transaction'] = df.loc[df['earned'] == 0].groupby(['client_id'])['amount'].mean().fillna(0)\n",
    "df['avg_sum_earned_per_transaction'] = df.loc[df['earned'] == 1].groupby(['client_id'])['amount'].mean().fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['var_sum_per_trans'] = df.groupby(['client_id'])['amount'].std().fillna(0)\n",
    "df['var_sum_spent_per_trans'] = df.loc[df['earned'] == 0].groupby(['client_id'])['amount'].std().fillna(0)\n",
    "df['var_sum_earned_per_trans'] = df.loc[df['earned'] == 1].groupby(['client_id'])['amount'].std().fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['transactions_per_day'] = df.groupby([df.index, 'day'])[\"day\"].transform(\"count\").fillna(0)\n",
    "df['transactions_per_day_spent'] = df.groupby(['client_id'])[\"day\"].transform(lambda x: x[x < 0].count()).fillna(0)\n",
    "df['transactions_per_day_earned'] = df.groupby(['client_id'])[\"day\"].transform(lambda x: x[x > 0].count()).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"var_amount_per_day\"] = df.groupby(['client_id','day'])['amount'].transform('std').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sum_per_day'] = df.groupby(['client_id', 'day'])['amount'].transform('sum').fillna(0)\n",
    "df['sum_per_day_spent'] = df.loc[df['earned'] == 0].groupby(['client_id', 'day'])['amount'].sum().fillna(0)\n",
    "df['sum_per_day_earned'] = df.loc[df['earned'] == 1].groupby(['client_id', 'day'])['amount'].sum().fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['terminal_unique'] = df.groupby(['client_id','term_id'])['term_id'].transform('count').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"var_time_transaction\"] = df.groupby(['client_id'])['time'].transform('std')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df['tr_unique_count'] = df.groupby(['client_id',\"trans_type\"])[\"trans_type\"].transform('count').fillna(0)\n",
    "df['tr_unique_sum'] = df.groupby(['client_id',\"trans_type\"])[\"trans_type\"].transform('sum').fillna(0)\n",
    "df['tr_unique_std'] = df.groupby(['client_id',\"trans_type\"])[\"trans_type\"].transform('std').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['mcc_unique_count'] = df.groupby(['client_id','mcc_code'])['mcc_code'].transform('count').fillna(0)\n",
    "df['mcc_unique_sum'] = df.groupby(['client_id','mcc_code'])['mcc_code'].transform('sum').fillna(0)\n",
    "df['mcc_unique_std'] = df.groupby(['client_id','mcc_code'])['mcc_code'].transform('std').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tr_unique_count'] = df.groupby(['client_id','trans_type'])['trans_type'].transform('count').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"total_amount_spend_to_earn\"] = np.divide(df[\"total_spent\"].abs(), df[\"total_earned\"].abs())\n",
    "df[\"total_amount_spend_to_earn\"].replace(np.inf, 1000, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(pd.get_dummies(data = df, columns = ['trans_type', 'mcc_code']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grouping by client_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols = df.select_dtypes(include=[np.number, np.bool_]).columns\n",
    "df_customers = df.groupby(['client_id'])[numeric_cols].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_customers['gender']\n",
    "X = df_customers.drop(['gender', 'amount', 'earned'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['total_earned'] = X['total_earned'].fillna(0)\n",
    "X['avg_sum_earned_per_transaction'] = X['avg_sum_earned_per_transaction'].fillna(0)\n",
    "X['total_spent'] = X['total_spent'].fillna(0)\n",
    "X['avg_sum_spent_per_transaction'] = X['avg_sum_spent_per_transaction'].fillna(0)\n",
    "X['var_sum_earned_per_trans'] = X['var_sum_earned_per_trans'].fillna(0)\n",
    "X['var_sum_spent_per_trans'] = X['var_sum_spent_per_trans'].fillna(0)\n",
    "X['var_time_transaction'] = X['var_time_transaction'].fillna(0)\n",
    "X['total_amount_spend_to_earn'] = X['total_amount_spend_to_earn'].fillna(0)\n",
    "# X['amount'] =  X['amount'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_features(X, X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the columns with missing values\n",
    "X = X.drop(['sum_per_day_spent', 'sum_per_day_earned'], axis = 1)\n",
    "missing_features(X, X.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb = CatBoostClassifier(depth= 4, iterations= 25, l2_leaf_reg= 0, learning_rate= 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_split = KFold(n_splits = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results = cross_validate(cb, X, y, scoring='roc_auc', cv=cv_split, return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results['test_score'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params = {\n",
    "#     'iterations': [5,10,15,20,25,30],\n",
    "#     'learning_rate': [0.5, 0.1, 0.05, 0.01],\n",
    "#     'l2_leaf_reg': [0.5, 0.1, 0.05, 0.01],\n",
    "#     'depth': [None,1,2,3,4,5],\n",
    "#     'l2_leaf_reg': [0,0.1,0.01]\n",
    "# }\n",
    "\n",
    "# cb_cv = GridSearchCV(cb, param_grid=params, scoring='roc_auc', cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cb_cv.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cb_cv.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = sorted(list(zip(X.columns,cb.feature_importances_.tolist())), key=itemgetter(1))\n",
    "feature_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove all features with importance <= 0.01\n",
    "important_features = [feature for feature, importance in feature_importance if importance > 0.01]\n",
    "X = X[important_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'iterations': [5,10,15,20,25,30],\n",
    "    'learning_rate': [0.5, 0.1, 0.05, 0.01],\n",
    "    'l2_leaf_reg': [0.5, 0.1, 0.05, 0.01],\n",
    "    'depth': [None,1,2,3,4,5],\n",
    "    'l2_leaf_reg': [0,0.1,0.01]\n",
    "}\n",
    "\n",
    "cb_cv = GridSearchCV(cb, param_grid=params, scoring='roc_auc', cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb_cv.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb = CatBoostClassifier(depth= 4, iterations= 30, l2_leaf_reg= 0.1, learning_rate= 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results = cross_validate(cb, X, y, scoring='roc_auc', cv=cv_split, return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results['test_score'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm_scaler = MinMaxScaler()\n",
    "scaled_X = mm_scaler.fit_transform(X)\n",
    "scaled_X = pd.DataFrame(scaled_X, columns = X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'n_estimators': [5,10,15,20,25,30,100],\n",
    "#     'learning_rate': [0.5, 0.1, 0.05, 0.01],\n",
    "#     'l2_leaf_reg': [0.5, 0.1, 0.05, 0.01],\n",
    "    'max_depth': [None,1,2,3,4,5],\n",
    "    'min_samples_split': [2,3,5,10],\n",
    "    'min_samples_leaf': [1,3,5,10],\n",
    "#     'l2_leaf_reg': [0,0.1,0.01]\n",
    "#     n_estimators=100,\n",
    "#     *,\n",
    "#     criterion='gini',\n",
    "}\n",
    "\n",
    "rf_cv = GridSearchCV(rf, param_grid=params, scoring='roc_auc', cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_cv.fit(scaled_X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(max_depth= None, min_samples_leaf= 5, min_samples_split= 10, n_estimators= 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_results = cross_validate(rf, X, y, scoring='roc_auc', cv=cv_split, return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_results['test_score'].mean()"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
